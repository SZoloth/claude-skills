# Teresa Torres' Continuous Discovery Framework

## Core Philosophy

Discovery is not a phase. It's a continuous practice integrated with delivery.

**Key principle:** Interview customers every week, as a team, to inform product decisions.

## The Product Trio

**Who:** Product Manager + Designer + Tech Lead (minimum)
**Why:** Viability + Desirability + Feasibility perspectives together
**Cadence:** Weekly customer interviews together

**Benefits:**
- Shared understanding (no game of telephone)
- Faster decisions (all perspectives present)
- Better solutions (diverse thinking)
- Team alignment (lived experience with customers)

## Opportunity Solution Trees

Visual framework for navigating product decisions.

```
Outcome (business goal)
    │
    ├── Opportunity 1 (customer need)
    │   ├── Solution 1a
    │   ├── Solution 1b
    │   └── Solution 1c
    │
    ├── Opportunity 2 (customer need)
    │   ├── Solution 2a
    │   └── Solution 2b
    │
    └── Opportunity 3 (customer need)
        └── Solution 3a
```

**Build from top down:**
1. Define desired outcome (business goal)
2. Discover opportunities (unmet customer needs)
3. Generate solution ideas (how to address opportunities)
4. Run experiments (test assumptions)

## Discovery Cadence

### Weekly interviews
- Minimum 1 hour per week with customers
- Whole trio participates
- Focus on recent experiences, not hypotheticals
- Record and review together

### Continuous synthesis
- After each interview: debrief and extract opportunities
- Weekly: update opportunity solution tree
- Bi-weekly: assess what we've learned, what to test next

### Assumption mapping
- For each solution idea: what must be true for this to work?
- Rank assumptions by risk
- Design experiments to test riskiest assumptions first

## Interview Structure

### Story-based questions
"Tell me about the last time you [relevant activity]"

- Gets specific, real experience
- Reveals context and workarounds
- Uncovers pain points organically

### Follow-up probes
- "Tell me more about that"
- "What did you do next?"
- "How did that make you feel?"
- "How often does this happen?"

### Avoid
- Hypotheticals ("Would you use...?")
- Leading questions ("Don't you think...?")
- Feature requests ("What features do you want?")

## From Interviews to Opportunities

1. **Identify pain points** in customer stories
2. **Frame as opportunities** ("Help user accomplish X")
3. **Group related opportunities** into clusters
4. **Prioritize** by evidence strength and impact
5. **Add to opportunity tree** under relevant outcome

## Solution Generation

For each high-priority opportunity:

1. **Diverge:** Generate 10+ solution ideas (quantity over quality)
2. **Map assumptions:** What must be true for each solution?
3. **Compare:** Which solutions address opportunity best?
4. **Converge:** Select 2-3 most promising to test

**Don't jump to first solution.** Exploring options leads to better outcomes.

## Assumption Testing

### Types of assumptions
- **Value:** Will customers use/buy this?
- **Usability:** Can customers figure it out?
- **Feasibility:** Can we build this?
- **Viability:** Does this work for our business?

### Test methods (fastest to slowest)
1. Customer interviews
2. One-question surveys
3. Fake door tests (show in UI, doesn't exist yet)
4. Concierge MVP (manual delivery)
5. Wizard of Oz (fake automation, real experience)
6. Prototype tests
7. Alpha/beta releases

**Principle:** Test with minimum investment needed to reduce risk.

## Integration with Delivery

Discovery and delivery run in parallel, not sequentially.

### This week:
- Team delivers Sprint N
- Team discovers for Sprint N+2 or N+3

### Benefits:
- Always have validated work ready
- Reduce "what should we build next?" thrash
- Higher confidence in what's built

## Common Pitfalls

❌ **Research theater:** Interviewing to validate decisions already made
✅ **True discovery:** Open to changing direction based on learning

❌ **Analysis paralysis:** Endless research, no decisions
✅ **Rapid experimentation:** Test, learn, decide, iterate

❌ **PM as sole researcher:** Team doesn't build empathy
✅ **Trio together:** Shared understanding and alignment

❌ **One big launch:** High-risk, slow feedback
✅ **Small experiments:** Low-risk, fast learning

## Success Indicators

- Team talks to customers weekly (not monthly or quarterly)
- Product decisions grounded in customer evidence
- Opportunity solution tree actively maintained
- Experiments fail fast (not big launches that fail slow)
- Team has shared understanding of customer needs
- Roadmap evolves based on learning (not locked 6 months out)

## Getting Started

Week 1:
- Schedule first customer interview
- Create opportunity solution tree (start with outcome)
- Conduct interview as trio, debrief after

Week 2-4:
- Continue weekly interviews
- Add opportunities to tree after each interview
- Identify patterns across interviews

Month 2:
- Start generating solution options for top opportunities
- Design first assumption test
- Run experiment

Month 3:
- Continuous rhythm established
- Learning informing roadmap decisions
- Team comfortable with practice
